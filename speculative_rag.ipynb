{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speculative RAG: Enhancing RAG Through Drafting\n",
    "\n",
    "This notebook implements **Speculative RAG** based on Google Research's paper: [\"Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting\"](https://arxiv.org/abs/2407.08223)\n",
    "\n",
    "## What is Speculative RAG?\n",
    "\n",
    "Speculative RAG is an advanced approach that uses a **two-stage drafter-verifier architecture** to improve both accuracy and latency:\n",
    "\n",
    "- **Specialist Drafter**: A smaller, fine-tuned model generates multiple answer drafts with rationales **in parallel**, each working with **distinct document subsets**\n",
    "- **Generalist Verifier**: A larger model calculates **conditional generation probability** P(answer | rationale, documents, query) for each draft and selects the highest-confidence answer\n",
    "- **Distinct Document Partitioning**: Retrieved documents are split into **non-overlapping subsets**, with each drafter processing different documents to provide diverse perspectives\n",
    "- **Rationale-Based Scoring**: Each draft includes reasoning, which the verifier uses to compute conditional probabilities for answer verification\n",
    "\n",
    "## Key Differences from Standard RAG\n",
    "\n",
    "1. **Standard RAG**: Feeds all retrieved documents directly to a single LLM\n",
    "2. **Speculative RAG**: Uses a smaller specialist to draft multiple candidates from **distinct document subsets** in parallel, then a larger model verifies using **conditional probability** and selects the best one\n",
    "\n",
    "## Performance Benefits (from paper)\n",
    "\n",
    "- **12.97% accuracy improvement** on PubHealth dataset\n",
    "- **51% latency reduction** compared to standard RAG\n",
    "- State-of-the-art results on TriviaQA, MuSiQue, PubHealth, and ARC-Challenge\n",
    "\n",
    "## How It Works (Paper Algorithm)\n",
    "\n",
    "1. **Document Retrieval**: Semantic search finds top-k relevant documents\n",
    "2. **Document Partitioning**: Split documents into **distinct (non-overlapping) subsets** for parallel processing\n",
    "3. **Parallel Drafting**: Smaller specialist model generates answer drafts with rationales from each subset simultaneously\n",
    "4. **Verification**: Larger generalist model calculates P(answer | rationale, documents, query) for each draft using conditional probability\n",
    "5. **Selection**: Return the draft with the **highest conditional probability score**\n",
    "\n",
    "## Implementation Notes\n",
    "\n",
    "This implementation follows the paper's core algorithm:\n",
    "- **Drafter**: Uses GPT-4o-mini (smaller model) to generate drafts with rationales (paper uses fine-tuned Mistral-7B)\n",
    "- **Verifier**: Uses GPT-4o (larger model) to compute conditional probabilities via logprobs (paper uses Mixtral-8x7B)\n",
    "- **Document Partitioning**: Creates distinct, non-overlapping subsets as specified in the paper\n",
    "- **Probability Calculation**: Uses OpenAI API's logprobs to approximate P(answer | rationale, documents, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai numpy scikit-learn wikipedia-api -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from openai import AsyncOpenAI\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "from datetime import datetime\n",
    "import wikipediaapi\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API\n",
    "client = AsyncOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Base Setup\n",
    "\n",
    "Fetch and process Wikipedia article on Quantum Entanglement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wikipedia fetching and chunking functions defined\n"
     ]
    }
   ],
   "source": [
    "def fetch_wikipedia_article(page_title: str) -> str:\n",
    "    \"\"\"Fetch Wikipedia article content.\"\"\"\n",
    "    wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        user_agent='SpeculativeRAG/1.0 (Educational Purpose)'\n",
    "    )\n",
    "    \n",
    "    page = wiki.page(page_title)\n",
    "    \n",
    "    if not page.exists():\n",
    "        raise ValueError(f\"Wikipedia page '{page_title}' does not exist\")\n",
    "    \n",
    "    return page.text\n",
    "\n",
    "\n",
    "def chunk_text_by_sections(text: str, max_chunk_size: int = 500) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Chunk Wikipedia text into semantic sections.\n",
    "    \n",
    "    Args:\n",
    "        text: Full Wikipedia article text\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "        \n",
    "    Returns:\n",
    "        List of document dictionaries with id, content, and metadata\n",
    "    \"\"\"\n",
    "    # Split by section headers (lines that end with ==)\n",
    "    sections = re.split(r'\\n(?=\\w+.*?\\n=+)', text)\n",
    "    \n",
    "    documents = []\n",
    "    doc_id = 1\n",
    "    \n",
    "    for section in sections:\n",
    "        # Extract section title if present\n",
    "        lines = section.strip().split('\\n')\n",
    "        if len(lines) > 1 and '=' in lines[1]:\n",
    "            title = lines[0].strip()\n",
    "            content = '\\n'.join(lines[2:]).strip()\n",
    "        else:\n",
    "            title = \"Introduction\"\n",
    "            content = section.strip()\n",
    "        \n",
    "        # Skip empty sections\n",
    "        if not content:\n",
    "            continue\n",
    "        \n",
    "        # If section is too large, chunk it by paragraphs\n",
    "        if len(content) > max_chunk_size:\n",
    "            paragraphs = content.split('\\n\\n')\n",
    "            current_chunk = \"\"\n",
    "            \n",
    "            for para in paragraphs:\n",
    "                if len(current_chunk) + len(para) > max_chunk_size and current_chunk:\n",
    "                    documents.append({\n",
    "                        \"id\": doc_id,\n",
    "                        \"content\": current_chunk.strip(),\n",
    "                        \"metadata\": {\"section\": title, \"source\": \"wikipedia\"}\n",
    "                    })\n",
    "                    doc_id += 1\n",
    "                    current_chunk = para\n",
    "                else:\n",
    "                    current_chunk += \"\\n\\n\" + para if current_chunk else para\n",
    "            \n",
    "            # Add remaining content\n",
    "            if current_chunk.strip():\n",
    "                documents.append({\n",
    "                    \"id\": doc_id,\n",
    "                    \"content\": current_chunk.strip(),\n",
    "                    \"metadata\": {\"section\": title, \"source\": \"wikipedia\"}\n",
    "                })\n",
    "                doc_id += 1\n",
    "        else:\n",
    "            documents.append({\n",
    "                \"id\": doc_id,\n",
    "                \"content\": content,\n",
    "                \"metadata\": {\"section\": title, \"source\": \"wikipedia\"}\n",
    "            })\n",
    "            doc_id += 1\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "print(\"✓ Wikipedia fetching and chunking functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Wikipedia article: Quantum entanglement\n",
      "Chunking article into semantic sections...\n",
      "\n",
      "✓ Loaded 74 document chunks from Wikipedia\n",
      "\n",
      "First 3 chunks:\n",
      "\n",
      "--- Document 1 (Section: Introduction) ---\n",
      "Quantum entanglement is the phenomenon where the quantum state of each particle in a group cannot be described independently of the state of the others, even when the particles are separated by a larg...\n",
      "\n",
      "--- Document 2 (Section: Introduction) ---\n",
      "History\n",
      "Albert Einstein and Niels Bohr engaged in a long-running collegial dispute over the interpretation of quantum mechanics, now known as the Bohr–Einstein debates. During these debates, Einstein ...\n",
      "\n",
      "--- Document 3 (Section: Introduction) ---\n",
      "Concept\n",
      "Meaning of entanglement\n",
      "Just as energy is a resource that facilitates mechanical operations, entanglement is a resource that facilitates performing tasks that involve communication and computa...\n",
      "\n",
      "... and 71 more chunks\n"
     ]
    }
   ],
   "source": [
    "# Fetch and process Wikipedia article on Quantum Entanglement\n",
    "print(\"Fetching Wikipedia article: Quantum entanglement\")\n",
    "wiki_text = fetch_wikipedia_article(\"Quantum entanglement\")\n",
    "\n",
    "print(\"Chunking article into semantic sections...\")\n",
    "KNOWLEDGE_BASE = chunk_text_by_sections(wiki_text, max_chunk_size=500)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(KNOWLEDGE_BASE)} document chunks from Wikipedia\")\n",
    "print(f\"\\nFirst 3 chunks:\")\n",
    "for i, doc in enumerate(KNOWLEDGE_BASE[:3]):\n",
    "    print(f\"\\n--- Document {doc['id']} (Section: {doc['metadata']['section']}) ---\")\n",
    "    print(f\"{doc['content'][:200]}...\")\n",
    "    \n",
    "print(f\"\\n... and {len(KNOWLEDGE_BASE) - 3} more chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and Retrieval Functions\n",
    "\n",
    "Breaking down the retrieval pipeline into individual components for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ get_embedding function defined\n"
     ]
    }
   ],
   "source": [
    "async def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> List[float]:\n",
    "    \"\"\"Get embedding for a text using OpenAI's embedding model.\"\"\"\n",
    "    response = await client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "print(\"✓ get_embedding function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ get_embeddings_batch function defined\n"
     ]
    }
   ],
   "source": [
    "async def get_embeddings_batch(texts: List[str], model: str = \"text-embedding-3-small\") -> List[List[float]]:\n",
    "    \"\"\"Get embeddings for multiple texts in parallel.\"\"\"\n",
    "    tasks = [get_embedding(text, model) for text in texts]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "print(\"✓ get_embeddings_batch function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ retrieve_documents function defined\n"
     ]
    }
   ],
   "source": [
    "async def retrieve_documents(query: str, knowledge_base: List[Dict], top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Retrieve top-k relevant documents based on semantic similarity.\"\"\"\n",
    "    # Get query embedding\n",
    "    query_embedding = await get_embedding(query)\n",
    "    \n",
    "    # Get embeddings for all documents (in practice, these would be pre-computed)\n",
    "    doc_texts = [doc[\"content\"] for doc in knowledge_base]\n",
    "    doc_embeddings = await get_embeddings_batch(doc_texts)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(\n",
    "        [query_embedding],\n",
    "        doc_embeddings\n",
    "    )[0]\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    # Return documents with scores\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        doc = knowledge_base[idx].copy()\n",
    "        doc[\"similarity_score\"] = float(similarities[idx])\n",
    "        results.append(doc)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ retrieve_documents function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speculative RAG Components\n",
    "\n",
    "Breaking down the two-stage drafter-verifier architecture into individual components.\n",
    "\n",
    "### Part 1: RAGDrafter Class - Specialist Model for Draft Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAGDrafter class initialized\n"
     ]
    }
   ],
   "source": [
    "class RAGDrafter:\n",
    "    \"\"\"\n",
    "    Specialist drafter using a smaller model to generate answer drafts with rationales.\n",
    "    Corresponds to the fine-tuned Mistral-7B in the paper.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, client: AsyncOpenAI, model: str = \"gpt-4o-mini\"):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "\n",
    "print(\"✓ RAGDrafter class initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAGDrafter.generate_draft method defined\n"
     ]
    }
   ],
   "source": [
    "async def _rag_drafter_generate_draft(self, query: str, documents: List[Dict], draft_id: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a single answer draft with rationale from a document subset.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        documents: Subset of retrieved documents for this draft\n",
    "        draft_id: Identifier for this draft\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing answer, rationale, and metadata\n",
    "    \"\"\"\n",
    "    # Format documents as context\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {i+1}:\\n{doc['content']}\" \n",
    "        for i, doc in enumerate(documents)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You are a specialist RAG drafter. Generate a concise answer to the question based ONLY on the provided documents.\n",
    "\n",
    "Context Documents:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Provide your response in this JSON format:\n",
    "{{\n",
    "    \"answer\": \"Your concise answer based on the documents\",\n",
    "    \"rationale\": \"Brief explanation of which documents you used and why this answer is correct\",\n",
    "    \"confidence\": \"A brief assessment of how well the documents support this answer\"\n",
    "}}\n",
    "\n",
    "Important: Only use information from the provided documents. If the documents don't contain enough information, acknowledge this in your rationale.\"\"\"\n",
    "    \n",
    "    response = await self.client.chat.completions.create(\n",
    "        model=self.model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,  # Low temperature for consistency\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    draft_data = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    return {\n",
    "        \"draft_id\": draft_id,\n",
    "        \"answer\": draft_data.get(\"answer\", \"\"),\n",
    "        \"rationale\": draft_data.get(\"rationale\", \"\"),\n",
    "        \"confidence_note\": draft_data.get(\"confidence\", \"\"),\n",
    "        \"documents_used\": [doc['id'] for doc in documents],\n",
    "        \"tokens\": response.usage.total_tokens,\n",
    "        \"model\": self.model\n",
    "    }\n",
    "\n",
    "# Add method to RAGDrafter class\n",
    "RAGDrafter.generate_draft = _rag_drafter_generate_draft\n",
    "\n",
    "print(\"✓ RAGDrafter.generate_draft method defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAGDrafter.generate_drafts_parallel method defined\n"
     ]
    }
   ],
   "source": [
    "async def _rag_drafter_generate_drafts_parallel(self, query: str, document_subsets: List[List[Dict]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate multiple drafts in parallel, each from a different document subset.\n",
    "    This is the key to Speculative RAG's latency improvement.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        document_subsets: List of document subsets, one for each draft\n",
    "        \n",
    "    Returns:\n",
    "        List of draft dictionaries\n",
    "    \"\"\"\n",
    "    tasks = [\n",
    "        self.generate_draft(query, subset, i)\n",
    "        for i, subset in enumerate(document_subsets)\n",
    "    ]\n",
    "    \n",
    "    drafts = await asyncio.gather(*tasks)\n",
    "    return drafts\n",
    "\n",
    "# Add method to RAGDrafter class\n",
    "RAGDrafter.generate_drafts_parallel = _rag_drafter_generate_drafts_parallel\n",
    "\n",
    "print(\"✓ RAGDrafter.generate_drafts_parallel method defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: RAGVerifier - Generalist Model for Draft Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAGVerifier class initialized\n"
     ]
    }
   ],
   "source": [
    "class RAGVerifier:\n",
    "    \"\"\"\n",
    "    Generalist verifier using a larger model to score and select the best draft.\n",
    "    Corresponds to the Mixtral-8x7B model in the paper.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, client: AsyncOpenAI, model: str = \"gpt-4o\"):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "\n",
    "print(\"✓ RAGVerifier class initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAGVerifier.verify_and_select method defined (with conditional probability scoring)\n"
     ]
    }
   ],
   "source": [
    "async def _rag_verifier_verify_and_select(self, query: str, drafts: List[Dict], all_documents: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Verify drafts and select the best one based on conditional generation probability.\n",
    "    \n",
    "    Following the paper: Calculate P(answer | rationale, documents, query) for each draft.\n",
    "    The verifier computes the conditional probability of generating each answer given its rationale,\n",
    "    the documents, and the query, then selects the draft with highest probability.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        drafts: List of draft answers with rationales\n",
    "        all_documents: All retrieved documents for reference\n",
    "        \n",
    "    Returns:\n",
    "        Selected draft with verification metadata\n",
    "    \"\"\"\n",
    "    # Calculate conditional probability for each draft\n",
    "    draft_scores = []\n",
    "    \n",
    "    for draft in drafts:\n",
    "        # Format the context: documents + rationale + query\n",
    "        docs_for_draft = [doc for doc in all_documents if doc['id'] in draft['documents_used']]\n",
    "        context_text = \"\\n\\n\".join([\n",
    "            f\"Document {doc['id']}: {doc['content']}\"\n",
    "            for doc in docs_for_draft\n",
    "        ])\n",
    "        \n",
    "        # Build verification prompt: Given documents, query, and rationale, \n",
    "        # calculate probability of the answer\n",
    "        verification_prompt = f\"\"\"Given the following context, question, and reasoning, verify this answer.\n",
    "\n",
    "Context Documents:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Reasoning: {draft['rationale']}\n",
    "\n",
    "Proposed Answer: {draft['answer']}\n",
    "\n",
    "Is this answer correct and well-supported by the documents and reasoning? Respond with only 'yes' or 'no'.\"\"\"\n",
    "        \n",
    "        # Get model's probability assessment\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": verification_prompt}],\n",
    "            temperature=0.0,\n",
    "            max_tokens=10,\n",
    "            logprobs=True,\n",
    "            top_logprobs=5\n",
    "        )\n",
    "        \n",
    "        # Calculate confidence score from logprobs\n",
    "        # Higher logprob = higher confidence in the answer\n",
    "        if response.choices[0].logprobs and response.choices[0].logprobs.content:\n",
    "            first_token_logprobs = response.choices[0].logprobs.content[0].top_logprobs\n",
    "            \n",
    "            # Find 'yes' token probability\n",
    "            yes_prob = 0.0\n",
    "            for token_logprob in first_token_logprobs:\n",
    "                if token_logprob.token.lower().strip() in ['yes', 'y']:\n",
    "                    yes_prob = np.exp(token_logprob.logprob)\n",
    "                    break\n",
    "            \n",
    "            confidence = yes_prob\n",
    "        else:\n",
    "            # Fallback if logprobs not available\n",
    "            confidence = 0.5\n",
    "        \n",
    "        draft_scores.append({\n",
    "            \"draft_id\": draft['draft_id'],\n",
    "            \"score\": float(confidence),\n",
    "            \"answer\": draft['answer'],\n",
    "            \"rationale\": draft['rationale']\n",
    "        })\n",
    "    \n",
    "    # Select draft with highest conditional probability\n",
    "    best_draft = max(draft_scores, key=lambda x: x['score'])\n",
    "    selected_idx = best_draft['draft_id']\n",
    "    \n",
    "    return {\n",
    "        \"selected_draft\": drafts[selected_idx],\n",
    "        \"confidence_score\": best_draft['score'],\n",
    "        \"verification_reasoning\": f\"Selected draft {selected_idx + 1} with conditional probability score of {best_draft['score']:.3f}\",\n",
    "        \"all_draft_scores\": draft_scores,\n",
    "        \"verifier_tokens\": sum(1 for _ in draft_scores) * 50,  # Approximate\n",
    "        \"verifier_model\": self.model\n",
    "    }\n",
    "\n",
    "# Add method to RAGVerifier class\n",
    "RAGVerifier.verify_and_select = _rag_verifier_verify_and_select\n",
    "\n",
    "print(\"✓ RAGVerifier.verify_and_select method defined (with conditional probability scoring)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speculative RAG Orchestrator\n",
    "\n",
    "Coordinates the full drafter-verifier pipeline with document partitioning and parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SpeculativeRAG.partition_documents method defined (distinct, non-overlapping subsets)\n"
     ]
    }
   ],
   "source": [
    "def _speculative_rag_partition_documents(self, documents: List[Dict], num_partitions: int = 3) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Partition documents into DISTINCT subsets for parallel draft generation.\n",
    "    \n",
    "    Per the paper: \"Each draft is generated from a distinct subset of retrieved documents,\n",
    "    providing diverse perspectives.\"\n",
    "    \n",
    "    Strategy: Create non-overlapping subsets to ensure each draft sees different documents.\n",
    "    This provides diverse perspectives and reduces token counts per draft.\n",
    "    \n",
    "    Args:\n",
    "        documents: Retrieved documents sorted by relevance\n",
    "        num_partitions: Number of distinct subsets to create\n",
    "        \n",
    "    Returns:\n",
    "        List of non-overlapping document subsets\n",
    "    \"\"\"\n",
    "    if len(documents) < num_partitions:\n",
    "        # If we have fewer docs than partitions, give each partition what we can\n",
    "        subsets = []\n",
    "        for i in range(num_partitions):\n",
    "            if i < len(documents):\n",
    "                subsets.append([documents[i]])\n",
    "            else:\n",
    "                # For extra partitions, use empty list (will be handled in draft generation)\n",
    "                subsets.append([])\n",
    "        return subsets\n",
    "    \n",
    "    # Create DISTINCT (non-overlapping) partitions as per the paper\n",
    "    partition_size = len(documents) // num_partitions\n",
    "    remainder = len(documents) % num_partitions\n",
    "    \n",
    "    subsets = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in range(num_partitions):\n",
    "        # Distribute remainder documents across first partitions\n",
    "        current_size = partition_size + (1 if i < remainder else 0)\n",
    "        end_idx = start_idx + current_size\n",
    "        \n",
    "        subset = documents[start_idx:end_idx]\n",
    "        subsets.append(subset)\n",
    "        \n",
    "        start_idx = end_idx\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "# Add method to SpeculativeRAG class\n",
    "SpeculativeRAG.partition_documents = _speculative_rag_partition_documents\n",
    "\n",
    "print(\"✓ SpeculativeRAG.partition_documents method defined (distinct, non-overlapping subsets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Speculative RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 6 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "\n",
      "================================================================================\n",
      "SPECULATIVE RAG RESULT\n",
      "================================================================================\n",
      "\n",
      "Question: What is quantum entanglement and how does it work?\n",
      "\n",
      "SELECTED ANSWER:\n",
      "Quantum entanglement is a phenomenon where the quantum state of particles cannot be described independently, leading to strong correlations in measurements of their properties, even when separated by large distances. It occurs when particles interact in such a way that their states become interdependent, and measurements on one particle instantaneously affect the state of the other. This phenomenon is distinct from classical correlations and is a fundamental feature of quantum mechanics.\n",
      "\n",
      "Rationale: This answer is based on Document 1, which explains the nature of quantum entanglement, its implications, and the correlations observed in measurements. Document 2 further elaborates on the concept of entanglement, describing how it works and the conditions under which it occurs. Together, these documents provide a comprehensive understanding of quantum entanglement.\n",
      "\n",
      "Confidence Score: 0.90\n",
      "Verification Reasoning: Draft 1 provides a clear and accurate explanation of quantum entanglement, focusing on the fundamental aspects of the phenomenon as described in the documents. It correctly highlights the interdependence of quantum states and the non-classical correlations that arise from entanglement, which are central to understanding how it works. The rationale cites Document 1, which is appropriate as it contains detailed information on the nature and implications of quantum entanglement. Draft 1 is comprehensive and directly addresses the question without introducing extraneous details.\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE METRICS\n",
      "================================================================================\n",
      "\n",
      "Total Time: 11.68s\n",
      "  - Retrieval: 1.62s\n",
      "  - Drafting (3 drafts in parallel): 3.85s\n",
      "  - Verification: 6.21s\n",
      "\n",
      "Drafts generated in parallel: 3.85s (vs ~11.54s sequential)\n",
      "\n",
      "Total Tokens: 7512\n",
      "  - Drafter (gpt-4o-mini): 3698\n",
      "  - Verifier (gpt-4o): 3814\n",
      "\n",
      "================================================================================\n",
      "ALL DRAFTS GENERATED\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Draft 1:\n",
      "Documents Used: [1, 3]\n",
      "Score: 0.9\n",
      "\n",
      "Answer: Quantum entanglement is a phenomenon where the quantum state of particles cannot be described independently, leading to strong correlations in measurements of their properties, even when separated by large distances. It occurs when particles interact in such a way that their states become interdependent, and measurements on one particle instantaneously affect the state of the other. This phenomenon is distinct from classical correlations and is a fundamental feature of quantum mechanics.\n",
      "\n",
      "Rationale: This answer is based on Document 1, which explains the nature of quantum entanglement, its implications, and the correlations observed in measurements. Document 2 further elaborates on the concept of entanglement, describing how it works and the conditions under which it occurs. Together, these documents provide a comprehensive understanding of quantum entanglement.\n",
      "Issues Noted: None. The draft is accurate, relevant, and well-supported by the documents.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Draft 2:\n",
      "Documents Used: [56, 33]\n",
      "Score: 0.7\n",
      "\n",
      "Answer: Quantum entanglement is a phenomenon in which two quantum systems become interconnected such that the state of one system instantly influences the state of the other, regardless of the distance between them. It is considered a valuable resource in quantum information theory, enabling tasks like quantum teleportation, where a quantum state can be transferred from one location to another using entangled states and classical communication.\n",
      "\n",
      "Rationale: This answer is based on Document 1, which describes entanglement's role in quantum teleportation and its applications, and Document 2, which explains entangled states as a resource that allows for transformations through local operations and classical communication. The documents collectively provide a clear definition and explanation of how entanglement operates.\n",
      "Issues Noted: While the draft accurately describes entanglement and its applications, it focuses more on the resource aspect and applications like quantum teleportation, which are not the primary focus of the question. The rationale cites Document 56 and 33, which are more about applications rather than the fundamental workings of entanglement.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Draft 3:\n",
      "Documents Used: [2, 72]\n",
      "Score: 0.8\n",
      "\n",
      "Answer: Quantum entanglement is a phenomenon where two or more quantum systems become interconnected such that the state of one system instantaneously influences the state of the other, regardless of the distance separating them. This concept was notably discussed in the context of the EPR paradox and further defined by Schrödinger, who described it as a characteristic trait of quantum mechanics. Experimental demonstrations of entanglement have been conducted, including the creation of entangled particle pairs and the violation of Bell's inequalities, which highlight the non-classical correlations between entangled systems.\n",
      "\n",
      "Rationale: This answer is based on Document 1, which provides a historical overview of quantum entanglement, including its definition, significance, and experimental validation. Document 2 adds information about recent advancements in entangling macroscopic objects but does not change the fundamental understanding of quantum entanglement. Therefore, Document 1 sufficiently supports the answer.\n",
      "Issues Noted: This draft provides a good historical context and mentions experimental validations, but it slightly overemphasizes the historical aspect rather than explaining how entanglement works. The rationale cites Document 2 and 72, but Document 72 is not directly relevant to the fundamental explanation of entanglement.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Speculative RAG query\n",
    "question = \"What is quantum entanglement and how does it work?\"\n",
    "\n",
    "result = await spec_rag.query(\n",
    "    question=question,\n",
    "    knowledge_base=KNOWLEDGE_BASE,\n",
    "    top_k=6,\n",
    "    num_drafts=3\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SPECULATIVE RAG RESULT\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Question: {result['question']}\\n\")\n",
    "\n",
    "print(f\"SELECTED ANSWER:\")\n",
    "print(f\"{result['answer']}\\n\")\n",
    "\n",
    "print(f\"Rationale: {result['rationale']}\\n\")\n",
    "\n",
    "print(f\"Confidence Score: {result['confidence_score']:.2f}\")\n",
    "print(f\"Verification Reasoning: {result['verification_reasoning']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"PERFORMANCE METRICS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Total Time: {result['timing']['total']:.2f}s\")\n",
    "print(f\"  - Retrieval: {result['timing']['retrieval']:.2f}s\")\n",
    "print(f\"  - Drafting ({len(result['all_drafts'])} drafts in parallel): {result['timing']['drafting']:.2f}s\")\n",
    "print(f\"  - Verification: {result['timing']['verification']:.2f}s\")\n",
    "print(f\"\\n{result['timing']['speedup_from_parallel']}\\n\")\n",
    "\n",
    "print(f\"Total Tokens: {result['tokens']['total']}\")\n",
    "print(f\"  - Drafter ({result['models_used']['drafter']}): {result['tokens']['drafter_total']}\")\n",
    "print(f\"  - Verifier ({result['models_used']['verifier']}): {result['tokens']['verifier']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ALL DRAFTS GENERATED\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for i, draft in enumerate(result['all_drafts']):\n",
    "    score_info = next((s for s in result['draft_scores'] if s['draft_id'] == i), {})\n",
    "    print(f\"\\nDraft {i+1}:\")\n",
    "    print(f\"Documents Used: {draft['documents_used']}\")\n",
    "    print(f\"Score: {score_info.get('score', 'N/A')}\")\n",
    "    print(f\"\\nAnswer: {draft['answer']}\")\n",
    "    print(f\"\\nRationale: {draft['rationale']}\")\n",
    "    if score_info.get('issues'):\n",
    "        print(f\"Issues Noted: {score_info['issues']}\")\n",
    "    print(f\"\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Speculative RAG Query\n",
    "\n",
    "Demonstrating the drafter-verifier pipeline with document partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 6 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 4 subsets...\n",
      "Generating 4 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "\n",
      "================================================================================\n",
      "DOCUMENT PARTITIONING ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Question: What is the EPR paradox and how does it relate to quantum entanglement?\n",
      "\n",
      "Document Subsets Created:\n",
      "\n",
      "Subset 1: Documents [4, 1]\n",
      "  - Doc 4: Paradox\n",
      "The singlet state described above is the basis for one version of the EP...\n",
      "  - Doc 1: Quantum entanglement is the phenomenon where the quantum state of each particle ...\n",
      "\n",
      "Subset 2: Documents [2, 14]\n",
      "  - Doc 2: History\n",
      "Albert Einstein and Niels Bohr engaged in a long-running collegial dispu...\n",
      "  - Doc 14: If the composite system is in this state, it is impossible to attribute to eithe...\n",
      "\n",
      "Subset 3: Documents [3]\n",
      "  - Doc 3: Concept\n",
      "Meaning of entanglement\n",
      "Just as energy is a resource that facilitates me...\n",
      "\n",
      "Subset 4: Documents [5]\n",
      "  - Doc 5: Failure of local hidden-variable theories\n",
      "A possible resolution to the paradox i...\n",
      "\n",
      "================================================================================\n",
      "DRAFT COMPARISON\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Draft 1 (Documents: [4, 1])\n",
      "Score: 0.7\n",
      "Answer: The EPR paradox, introduced by Einstein, Podolsky, and Rosen, highlights the seemingly paradoxical nature of quantum entanglement, where the quantum state of entangled particles cannot be described in...\n",
      "Rationale: This answer is based on Document 1, which explains the EPR paradox and its implications regarding measurements on entangled particles, and Document 2,...\n",
      "\n",
      "Draft 2 (Documents: [2, 14])\n",
      "Score: 0.9\n",
      "Answer: The EPR paradox, formulated by Einstein, Podolsky, and Rosen in 1935, is a thought experiment that argues that quantum mechanics cannot fully describe physical reality, as it suggests that two entangl...\n",
      "Rationale: This answer is based on Document 1, which describes the EPR paradox and its implications for quantum mechanics and entanglement. It explains how the p...\n",
      "\n",
      "Draft 3 (Documents: [3])\n",
      "Score: 0.6\n",
      "Answer: The documents do not explicitly define the EPR paradox, but they describe quantum entanglement, which is central to the paradox. The EPR paradox highlights the strange implications of entanglement, wh...\n",
      "Rationale: The answer is based on the explanation of entanglement in Document 1, which discusses how measurements on entangled particles are correlated. While th...\n",
      "\n",
      "Draft 4 (Documents: [5])\n",
      "Score: 0.8\n",
      "Answer: The EPR paradox arises from the implications of quantum entanglement, where two particles can exhibit correlated properties (like spin) regardless of the distance separating them. This challenges clas...\n",
      "Rationale: This answer is based on Document 1, which discusses the failure of local hidden-variable theories in the context of quantum measurements and the impli...\n",
      "\n",
      "================================================================================\n",
      "FINAL SELECTION\n",
      "================================================================================\n",
      "\n",
      "Selected Answer:\n",
      "The EPR paradox, formulated by Einstein, Podolsky, and Rosen in 1935, is a thought experiment that argues that quantum mechanics cannot fully describe physical reality, as it suggests that two entangled systems can instantaneously affect each other's states despite being spatially separated. This phenomenon highlights the concept of quantum entanglement, where the measurement of one system's state determines the state of another, leading to perfectly anti-correlated results, as demonstrated in the context of entangled particles.\n",
      "\n",
      "Confidence: 0.90\n",
      "Why: Draft 2 provides a comprehensive and accurate explanation of the EPR paradox and its relation to quantum entanglement. It correctly identifies the historical context and the implications of the paradox on the understanding of quantum mechanics. The draft uses relevant documents effectively, particularly Document 1 and Document 2, to support its explanation. It also addresses the concept of anti-correlated results in entangled systems, which is a key aspect of the EPR paradox.\n"
     ]
    }
   ],
   "source": [
    "# Analyze how document partitioning affects draft quality\n",
    "question2 = \"What is the EPR paradox and how does it relate to quantum entanglement?\"\n",
    "\n",
    "result2 = await spec_rag.query(\n",
    "    question=question2,\n",
    "    knowledge_base=KNOWLEDGE_BASE,\n",
    "    top_k=6,\n",
    "    num_drafts=4  # Generate 4 drafts for comparison\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DOCUMENT PARTITIONING ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Question: {result2['question']}\\n\")\n",
    "\n",
    "print(\"Document Subsets Created:\")\n",
    "for i, subset_ids in enumerate(result2['document_subsets']):\n",
    "    print(f\"\\nSubset {i+1}: Documents {subset_ids}\")\n",
    "    # Show which documents these are\n",
    "    docs_in_subset = [doc for doc in result2['retrieved_documents'] if doc['id'] in subset_ids]\n",
    "    for doc in docs_in_subset:\n",
    "        print(f\"  - Doc {doc['id']}: {doc['content'][:80]}...\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DRAFT COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for i, draft in enumerate(result2['all_drafts']):\n",
    "    score_info = next((s for s in result2['draft_scores'] if s['draft_id'] == i), {})\n",
    "    \n",
    "    print(f\"\\nDraft {i+1} (Documents: {draft['documents_used']})\")\n",
    "    print(f\"Score: {score_info.get('score', 'N/A')}\")\n",
    "    print(f\"Answer: {draft['answer'][:200]}...\")\n",
    "    print(f\"Rationale: {draft['rationale'][:150]}...\")\n",
    "    \n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FINAL SELECTION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Selected Answer:\\n{result2['answer']}\\n\")\n",
    "print(f\"Confidence: {result2['confidence_score']:.2f}\")\n",
    "print(f\"Why: {result2['verification_reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Comparing Draft Quality\n",
    "\n",
    "Examining how different document subsets lead to different draft answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Speculative RAG on 3 questions...\n",
      "\n",
      "[1/3] What is Bell's theorem and its significance?\n",
      "Retrieving top 5 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "  ✓ Completed in 12.20s\n",
      "\n",
      "[2/3] How was quantum entanglement experimentally verified?\n",
      "Retrieving top 5 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "  ✓ Completed in 11.55s\n",
      "\n",
      "[3/3] What are the applications of quantum entanglement in quantum computing?\n",
      "Retrieving top 5 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "  ✓ Completed in 13.70s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Query                                              Time (s)     Tokens     Confidence\n",
      "------------------------------------------------------------------------------------------\n",
      "What is Bell's theorem and its significance?       12.20        5606       0.90\n",
      "How was quantum entanglement experimentally ver... 11.55        5610       0.90\n",
      "What are the applications of quantum entangleme... 13.70        6930       0.90\n",
      "------------------------------------------------------------------------------------------\n",
      "TOTALS                                             37.44        18146     \n",
      "\n",
      "Average per query: 12.48s, 6048 tokens\n",
      "Total drafts generated: 9\n",
      "Average drafting time: 2.94s\n",
      "Average verification time: 7.10s\n"
     ]
    }
   ],
   "source": [
    "# Test multiple queries to analyze performance patterns\n",
    "test_questions = [\n",
    "    \"What is Bell's theorem and its significance?\",\n",
    "    \"How was quantum entanglement experimentally verified?\",\n",
    "    \"What are the applications of quantum entanglement in quantum computing?\"\n",
    "]\n",
    "\n",
    "print(f\"Running Speculative RAG on {len(test_questions)} questions...\\n\")\n",
    "\n",
    "results = []\n",
    "for i, question in enumerate(test_questions):\n",
    "    print(f\"[{i+1}/{len(test_questions)}] {question}\")\n",
    "    result = await spec_rag.query(question, KNOWLEDGE_BASE, top_k=5, num_drafts=3)\n",
    "    results.append(result)\n",
    "    print(f\"  ✓ Completed in {result['timing']['total']:.2f}s\\n\")\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PERFORMANCE SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "total_tokens = 0\n",
    "total_duration = 0\n",
    "total_drafts = 0\n",
    "\n",
    "print(f\"{'Query':<50} {'Time (s)':<12} {'Tokens':<10} {'Confidence'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    tokens = result['tokens']['total']\n",
    "    duration = result['timing']['total']\n",
    "    conf = result['confidence_score']\n",
    "    \n",
    "    total_tokens += tokens\n",
    "    total_duration += duration\n",
    "    total_drafts += len(result['all_drafts'])\n",
    "    \n",
    "    q_short = result['question'][:47] + \"...\" if len(result['question']) > 50 else result['question']\n",
    "    print(f\"{q_short:<50} {duration:<12.2f} {tokens:<10} {conf:.2f}\")\n",
    "\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'TOTALS':<50} {total_duration:<12.2f} {total_tokens:<10}\")\n",
    "print(f\"\\nAverage per query: {total_duration/len(results):.2f}s, {total_tokens//len(results)} tokens\")\n",
    "print(f\"Total drafts generated: {total_drafts}\")\n",
    "print(f\"Average drafting time: {sum(r['timing']['drafting'] for r in results)/len(results):.2f}s\")\n",
    "print(f\"Average verification time: {sum(r['timing']['verification'] for r in results)/len(results):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Performance Analysis Across Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 6 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "\n",
      "================================================================================\n",
      "DETAILED SPECULATIVE RAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Question: What is quantum entanglement swapping and how does it work?\n",
      "\n",
      "================================================================================\n",
      "STEP 1: DOCUMENT RETRIEVAL\n",
      "================================================================================\n",
      "\n",
      "Retrieved 6 documents:\n",
      "\n",
      "Doc 34 (similarity: 0.731):\n",
      "  Entanglement swapping is variant of teleportation that allows two parties that have never interacted to share an entangl...\n",
      "\n",
      "Doc 1 (similarity: 0.599):\n",
      "  Quantum entanglement is the phenomenon where the quantum state of each particle in a group cannot be described independe...\n",
      "\n",
      "Doc 33 (similarity: 0.590):\n",
      "  Entanglement as a resource\n",
      "In quantum information theory, entangled states are considered a 'resource', i.e., something ...\n",
      "\n",
      "Doc 56 (similarity: 0.578):\n",
      "  Applications\n",
      "Entanglement has many applications in quantum information theory. With the aid of entanglement, otherwise i...\n",
      "\n",
      "Doc 65 (similarity: 0.572):\n",
      "  Methods of creating entanglement\n",
      "Entanglement is usually created by direct interactions between subatomic particles. The...\n",
      "\n",
      "Doc 2 (similarity: 0.567):\n",
      "  History\n",
      "Albert Einstein and Niels Bohr engaged in a long-running collegial dispute over the interpretation of quantum me...\n",
      "\n",
      "================================================================================\n",
      "STEP 2: DOCUMENT PARTITIONING\n",
      "================================================================================\n",
      "\n",
      "Subset 1: Documents [34, 1]\n",
      "Subset 2: Documents [33, 56]\n",
      "Subset 3: Documents [65, 2]\n",
      "\n",
      "================================================================================\n",
      "STEP 3: PARALLEL DRAFT GENERATION\n",
      "================================================================================\n",
      "\n",
      "Generated 3 drafts in 3.18s\n",
      "(Sequential would take ~9.53s)\n",
      "\n",
      "\n",
      "Draft 1:\n",
      "  Documents: [34, 1]\n",
      "  Tokens: 1041\n",
      "  Answer: Quantum entanglement swapping is a process that allows two parties, who have never interacted, to sh...\n",
      "\n",
      "Draft 2:\n",
      "  Documents: [33, 56]\n",
      "  Tokens: 827\n",
      "  Answer: The provided documents do not contain information about quantum entanglement swapping....\n",
      "\n",
      "Draft 3:\n",
      "  Documents: [65, 2]\n",
      "  Tokens: 1344\n",
      "  Answer: Quantum entanglement swapping is a method of creating entanglement between quantum systems that have...\n",
      "\n",
      "================================================================================\n",
      "STEP 4: VERIFICATION & SELECTION\n",
      "================================================================================\n",
      "\n",
      "Verification completed in 6.06s\n",
      "Tokens used: 3256\n",
      "\n",
      "Draft Scores:\n",
      "  Draft 1: 0.90\n",
      "    Issues: Minor error in rationale citation; should reference Document 34 instead of Document 1.\n",
      "  Draft 2: 0.20\n",
      "    Issues: Incorrectly claims that the documents do not contain information about entanglement swapping, missing the relevant content in Document 34.\n",
      "  Draft 3: 0.70\n",
      "    Issues: Provides a correct but less detailed explanation of entanglement swapping. The rationale incorrectly cites Document 1 instead of Document 34, which is the correct source for the explanation.\n",
      "\n",
      "================================================================================\n",
      "FINAL ANSWER\n",
      "================================================================================\n",
      "\n",
      "Selected: Draft 1\n",
      "Confidence: 0.90\n",
      "\n",
      "Answer:\n",
      "Quantum entanglement swapping is a process that allows two parties, who have never interacted, to share an entangled state. It begins with two pairs of entangled particles (A, B) and (C, D). By measuring particles B and C in the Bell basis, the states of A and D collapse into an entangled state, despite no prior interaction. This enables interactions between qubits of A and B through teleportation, which consumes entangled states as a resource.\n",
      "\n",
      "Rationale:\n",
      "This answer is based on Document 1, which describes the entanglement swapping process in detail, including the initial setup with EPR sources, the measurement process, and the resulting entanglement. Document 2 provides background on quantum entanglement but does not specifically address the swapping process, making Document 1 the primary source for this answer.\n",
      "\n",
      "Verification Reasoning:\n",
      "Draft 1 provides a clear and accurate explanation of quantum entanglement swapping, directly referencing the process described in Document 34. It correctly outlines the setup with two pairs of entangled particles and the measurement process that leads to entanglement between previously non-interacting particles. The rationale correctly identifies Document 34 as the primary source, although it mistakenly mentions Document 1 instead of Document 34. Despite this minor error, the draft is factually accurate and relevant to the question.\n"
     ]
    }
   ],
   "source": [
    "# Try your own question with detailed analysis\n",
    "custom_question = \"What is quantum entanglement swapping and how does it work?\"\n",
    "\n",
    "result = await spec_rag.query(custom_question, KNOWLEDGE_BASE, top_k=6, num_drafts=3)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DETAILED SPECULATIVE RAG ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Question: {result['question']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STEP 1: DOCUMENT RETRIEVAL\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Retrieved {len(result['retrieved_documents'])} documents:\\n\")\n",
    "for doc in result['retrieved_documents']:\n",
    "    print(f\"Doc {doc['id']} (similarity: {doc['similarity_score']:.3f}):\")\n",
    "    print(f\"  {doc['content'][:120]}...\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STEP 2: DOCUMENT PARTITIONING\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for i, subset_ids in enumerate(result['document_subsets']):\n",
    "    print(f\"Subset {i+1}: Documents {subset_ids}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STEP 3: PARALLEL DRAFT GENERATION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Generated {len(result['all_drafts'])} drafts in {result['timing']['drafting']:.2f}s\")\n",
    "print(f\"(Sequential would take ~{result['timing']['drafting'] * len(result['all_drafts']):.2f}s)\\n\")\n",
    "\n",
    "for draft in result['all_drafts']:\n",
    "    print(f\"\\nDraft {draft['draft_id'] + 1}:\")\n",
    "    print(f\"  Documents: {draft['documents_used']}\")\n",
    "    print(f\"  Tokens: {draft['tokens']}\")\n",
    "    print(f\"  Answer: {draft['answer'][:100]}...\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STEP 4: VERIFICATION & SELECTION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Verification completed in {result['timing']['verification']:.2f}s\")\n",
    "print(f\"Tokens used: {result['tokens']['verifier']}\\n\")\n",
    "\n",
    "print(\"Draft Scores:\")\n",
    "for score in result['draft_scores']:\n",
    "    print(f\"  Draft {score['draft_id'] + 1}: {score['score']:.2f}\")\n",
    "    if score.get('issues'):\n",
    "        print(f\"    Issues: {score['issues']}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL ANSWER\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Selected: Draft {result['draft_scores'].index(max(result['draft_scores'], key=lambda x: x['score'])) + 1}\")\n",
    "print(f\"Confidence: {result['confidence_score']:.2f}\\n\")\n",
    "\n",
    "print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "\n",
    "print(f\"Rationale:\\n{result['rationale']}\\n\")\n",
    "\n",
    "print(f\"Verification Reasoning:\\n{result['verification_reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Custom Question with Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Standard RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Speculative RAG...\n",
      "Retrieving top 6 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "\n",
      "================================================================================\n",
      "STANDARD RAG vs SPECULATIVE RAG COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Question: What is the relationship between quantum entanglement and nonlocality?\n",
      "\n",
      "================================================================================\n",
      "STANDARD RAG\n",
      "================================================================================\n",
      "\n",
      "Model: gpt-4o\n",
      "Duration: 14.57s\n",
      "Tokens: 2993\n",
      "\n",
      "Answer:\n",
      "Quantum entanglement and nonlocality are closely related concepts in quantum mechanics, but they are not identical. Here's a comprehensive explanation of their relationship based on the provided documents:\n",
      "\n",
      "1. **Quantum Entanglement**: \n",
      "   - Quantum entanglement is a phenomenon where the quantum state of each particle in a group cannot be described independently of the state of the others, even when the particles are separated by large distances (Document 1). It is a fundamental feature of quantum mechanics that distinguishes it from classical mechanics.\n",
      "   - Entanglement results in strong correlations between measurements on entangled particles. For example, if two particles are entangled in such a way that their total spin is zero, measuring the spin of one particle will instantly determine the spin of the other, regardless of the distance between them (Document 1).\n",
      "   - Entanglement is considered a resource in quantum information theory, enabling tasks like quantum teleportation and enhancing communication and computation when combined with local operations and classical communication (LOCC) (Documents 3 and 33).\n",
      "\n",
      "2. **Nonlocality**:\n",
      "   - Nonlocality refers to the phenomenon where the results of measurements on entangled particles cannot be explained by local hidden variable theories, which assume that properties of particles are determined by local factors and do not involve any faster-than-light influences (Document 6).\n",
      "   - The violation of Bell inequalities is often associated with quantum nonlocality. Bell inequalities are mathematical inequalities that local hidden variable theories must satisfy. Quantum mechanics predicts and experiments confirm that these inequalities are violated, indicating that local hidden variable models cannot fully explain the observed correlations in entangled systems (Documents 1 and 70).\n",
      "   - Despite the term \"nonlocality,\" it is important to note that entanglement does not allow for faster-than-light communication, as the measurement outcomes are fundamentally random and cannot be controlled to transmit information (Document 1).\n",
      "\n",
      "3. **Relationship**:\n",
      "   - Entanglement is necessary for the violation of Bell inequalities, which is a hallmark of quantum nonlocality. However, not all entangled states exhibit nonlocality in the sense of violating Bell inequalities. For instance, Werner states are entangled but do not violate Bell inequalities because they can be described by local hidden variable models (Document 6).\n",
      "   - The term nonlocality is sometimes controversial because it suggests faster-than-light signals, but it has become a widespread convention to describe the failure of local hidden variable models to account for quantum mechanical predictions (Document 6).\n",
      "\n",
      "In summary, while quantum entanglement is a prerequisite for nonlocality, not all entangled states exhibit nonlocality as defined by the violation of Bell inequalities. Nonlocality highlights the inability of local hidden variable theories to explain the correlations observed in entangled systems, reinforcing the non-classical nature of quantum mechanics.\n",
      "\n",
      "================================================================================\n",
      "SPECULATIVE RAG\n",
      "================================================================================\n",
      "\n",
      "Models: gpt-4o-mini (drafter) + gpt-4o (verifier)\n",
      "Duration: 12.29s\n",
      "  - Drafting (parallel): 3.59s\n",
      "  - Verification: 6.84s\n",
      "Tokens: 6526\n",
      "  - Drafter: 3231\n",
      "  - Verifier: 3295\n",
      "Confidence: 0.90\n",
      "\n",
      "Answer:\n",
      "Quantum entanglement is a phenomenon where the states of particles are interdependent, leading to correlations that cannot be explained by local hidden variables, thus producing a violation of Bell inequalities, which is often referred to as nonlocality. However, the term nonlocality is controversial and does not imply faster-than-light communication.\n",
      "\n",
      "Rationale:\n",
      "This answer is based on Document 1, which discusses the violation of Bell inequalities and the concept of nonlocality, and Document 2, which explains quantum entanglement and its correlation effects. Together, they clarify the relationship between entanglement and nonlocality.\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Latency: Speculative RAG is 15.6% faster\n",
      "Token Usage: Speculative RAG uses 3533 more tokens\n",
      "\n",
      "Key Advantages of Speculative RAG:\n",
      "  1. Multiple draft perspectives increase robustness\n",
      "  2. Parallel drafting improves latency (when network-bound)\n",
      "  3. Verification step provides confidence scoring\n",
      "  4. Drafter specialization can improve accuracy with fine-tuning\n"
     ]
    }
   ],
   "source": [
    "async def standard_rag(question: str, documents: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Standard RAG baseline: feed all documents directly to a single LLM.\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {doc['id']}:\\n{doc['content']}\" \n",
    "        for doc in documents\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following context documents, answer the question.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a comprehensive answer based on the documents.\"\"\"\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Use same model as verifier for fair comparison\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    duration = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.choices[0].message.content,\n",
    "        \"tokens\": response.usage.total_tokens,\n",
    "        \"duration\": duration,\n",
    "        \"model\": \"gpt-4o\"\n",
    "    }\n",
    "\n",
    "\n",
    "# Compare both approaches\n",
    "test_question = \"What is the relationship between quantum entanglement and nonlocality?\"\n",
    "\n",
    "print(\"Running Standard RAG...\")\n",
    "retrieved = await retrieve_documents(test_question, KNOWLEDGE_BASE, top_k=6)\n",
    "standard_result = await standard_rag(test_question, retrieved)\n",
    "\n",
    "print(\"Running Speculative RAG...\")\n",
    "spec_result = await spec_rag.query(test_question, KNOWLEDGE_BASE, top_k=6, num_drafts=3)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STANDARD RAG vs SPECULATIVE RAG COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Question: {test_question}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STANDARD RAG\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"Model: {standard_result['model']}\")\n",
    "print(f\"Duration: {standard_result['duration']:.2f}s\")\n",
    "print(f\"Tokens: {standard_result['tokens']}\")\n",
    "print(f\"\\nAnswer:\\n{standard_result['answer']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"SPECULATIVE RAG\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"Models: {spec_result['models_used']['drafter']} (drafter) + {spec_result['models_used']['verifier']} (verifier)\")\n",
    "print(f\"Duration: {spec_result['timing']['total']:.2f}s\")\n",
    "print(f\"  - Drafting (parallel): {spec_result['timing']['drafting']:.2f}s\")\n",
    "print(f\"  - Verification: {spec_result['timing']['verification']:.2f}s\")\n",
    "print(f\"Tokens: {spec_result['tokens']['total']}\")\n",
    "print(f\"  - Drafter: {spec_result['tokens']['drafter_total']}\")\n",
    "print(f\"  - Verifier: {spec_result['tokens']['verifier']}\")\n",
    "print(f\"Confidence: {spec_result['confidence_score']:.2f}\")\n",
    "print(f\"\\nAnswer:\\n{spec_result['answer']}\\n\")\n",
    "print(f\"Rationale:\\n{spec_result['rationale']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "speedup = ((standard_result['duration'] - spec_result['timing']['total']) / standard_result['duration']) * 100\n",
    "token_diff = spec_result['tokens']['total'] - standard_result['tokens']\n",
    "\n",
    "print(f\"Latency: Speculative RAG is {abs(speedup):.1f}% {'faster' if speedup > 0 else 'slower'}\")\n",
    "print(f\"Token Usage: Speculative RAG uses {abs(token_diff)} {'more' if token_diff > 0 else 'fewer'} tokens\")\n",
    "print(f\"\\nKey Advantages of Speculative RAG:\")\n",
    "print(\"  1. Multiple draft perspectives increase robustness\")\n",
    "print(\"  2. Parallel drafting improves latency (when network-bound)\")\n",
    "print(\"  3. Verification step provides confidence scoring\")\n",
    "print(\"  4. Drafter specialization can improve accuracy with fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Speculative RAG vs Standard RAG\n",
    "\n",
    "Demonstrating the advantages of the drafter-verifier architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Standard RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Speculative RAG...\n",
      "Retrieving top 6 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/hhegadehallimadh/labs/crews/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning documents into 3 subsets...\n",
      "Generating 3 answer drafts in parallel using gpt-4o-mini...\n",
      "Verifying drafts and selecting best answer using gpt-4o...\n",
      "\n",
      "================================================================================\n",
      "STANDARD RAG vs SPECULATIVE RAG COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Question: What are transformers and how do they process data?\n",
      "\n",
      "================================================================================\n",
      "STANDARD RAG\n",
      "================================================================================\n",
      "\n",
      "Model: gpt-4o\n",
      "Duration: 1.19s\n",
      "Tokens: 1832\n",
      "\n",
      "Answer:\n",
      "The provided documents do not contain any information about transformers or how they process data. The documents focus on quantum entanglement, its applications, and its role as a resource in quantum information theory. If you have any other questions or need information on a different topic, feel free to ask!\n",
      "\n",
      "================================================================================\n",
      "SPECULATIVE RAG\n",
      "================================================================================\n",
      "\n",
      "Models: gpt-4o-mini (drafter) + gpt-4o (verifier)\n",
      "Duration: 9.36s\n",
      "  - Drafting (parallel): 2.59s\n",
      "  - Verification: 3.03s\n",
      "Tokens: 4743\n",
      "  - Drafter: 2356\n",
      "  - Verifier: 2387\n",
      "Confidence: 0.95\n",
      "\n",
      "Answer:\n",
      "The documents do not provide information on transformers or how they process data.\n",
      "\n",
      "Rationale:\n",
      "The provided documents focus on entanglement as a resource in quantum information theory, discussing its applications and implications, but do not mention transformers or data processing.\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Latency: Speculative RAG is 683.2% slower\n",
      "Token Usage: Speculative RAG uses 2911 more tokens\n",
      "\n",
      "Key Advantages of Speculative RAG:\n",
      "  1. Multiple draft perspectives increase robustness\n",
      "  2. Parallel drafting improves latency (when network-bound)\n",
      "  3. Verification step provides confidence scoring\n",
      "  4. Drafter specialization can improve accuracy with fine-tuning\n"
     ]
    }
   ],
   "source": [
    "async def standard_rag(question: str, documents: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Standard RAG baseline: feed all documents directly to a single LLM.\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {doc['id']}:\\n{doc['content']}\" \n",
    "        for doc in documents\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"Based on the following context documents, answer the question.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a comprehensive answer based on the documents.\"\"\"\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Use same model as verifier for fair comparison\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    duration = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.choices[0].message.content,\n",
    "        \"tokens\": response.usage.total_tokens,\n",
    "        \"duration\": duration,\n",
    "        \"model\": \"gpt-4o\"\n",
    "    }\n",
    "\n",
    "\n",
    "# Compare both approaches\n",
    "test_question = \"What are transformers and how do they process data?\"\n",
    "\n",
    "print(\"Running Standard RAG...\")\n",
    "retrieved = await retrieve_documents(test_question, KNOWLEDGE_BASE, top_k=6)\n",
    "standard_result = await standard_rag(test_question, retrieved)\n",
    "\n",
    "print(\"Running Speculative RAG...\")\n",
    "spec_result = await spec_rag.query(test_question, KNOWLEDGE_BASE, top_k=6, num_drafts=3)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STANDARD RAG vs SPECULATIVE RAG COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Question: {test_question}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STANDARD RAG\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"Model: {standard_result['model']}\")\n",
    "print(f\"Duration: {standard_result['duration']:.2f}s\")\n",
    "print(f\"Tokens: {standard_result['tokens']}\")\n",
    "print(f\"\\nAnswer:\\n{standard_result['answer']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"SPECULATIVE RAG\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"Models: {spec_result['models_used']['drafter']} (drafter) + {spec_result['models_used']['verifier']} (verifier)\")\n",
    "print(f\"Duration: {spec_result['timing']['total']:.2f}s\")\n",
    "print(f\"  - Drafting (parallel): {spec_result['timing']['drafting']:.2f}s\")\n",
    "print(f\"  - Verification: {spec_result['timing']['verification']:.2f}s\")\n",
    "print(f\"Tokens: {spec_result['tokens']['total']}\")\n",
    "print(f\"  - Drafter: {spec_result['tokens']['drafter_total']}\")\n",
    "print(f\"  - Verifier: {spec_result['tokens']['verifier']}\")\n",
    "print(f\"Confidence: {spec_result['confidence_score']:.2f}\")\n",
    "print(f\"\\nAnswer:\\n{spec_result['answer']}\\n\")\n",
    "print(f\"Rationale:\\n{spec_result['rationale']}\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "speedup = ((standard_result['duration'] - spec_result['timing']['total']) / standard_result['duration']) * 100\n",
    "token_diff = spec_result['tokens']['total'] - standard_result['tokens']\n",
    "\n",
    "print(f\"Latency: Speculative RAG is {abs(speedup):.1f}% {'faster' if speedup > 0 else 'slower'}\")\n",
    "print(f\"Token Usage: Speculative RAG uses {abs(token_diff)} {'more' if token_diff > 0 else 'fewer'} tokens\")\n",
    "print(f\"\\nKey Advantages of Speculative RAG:\")\n",
    "print(\"  1. Multiple draft perspectives increase robustness\")\n",
    "print(\"  2. Parallel drafting improves latency (when network-bound)\")\n",
    "print(\"  3. Verification step provides confidence scoring\")\n",
    "print(\"  4. Drafter specialization can improve accuracy with fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements **Speculative RAG** following Google Research's paper architecture:\n",
    "\n",
    "### Architecture\n",
    "\n",
    "1. **RAGDrafter**: Smaller specialist model (gpt-4o-mini) that generates multiple answer drafts with rationales, each from different document subsets\n",
    "2. **RAGVerifier**: Larger generalist model (gpt-4o) that scores drafts and selects the best answer based on quality and relevance\n",
    "3. **Parallel Processing**: Documents are partitioned and processed in parallel for latency reduction\n",
    "\n",
    "### Key Benefits from the Paper\n",
    "\n",
    "- **12.97% accuracy improvement** on PubHealth dataset\n",
    "- **51% latency reduction** compared to standard RAG\n",
    "- Better handling of diverse document sets through parallel draft generation\n",
    "- Confidence scoring via verification step\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "- **Drafter model**: Uses low temperature (0.3) for consistent drafting\n",
    "- **Verifier model**: Uses very low temperature (0.1) for reliable evaluation\n",
    "- **Document partitioning**: Creates overlapping subsets to ensure adequate context\n",
    "- **Rationale-based scoring**: Each draft includes reasoning that the verifier uses for assessment\n",
    "\n",
    "### Potential Improvements\n",
    "\n",
    "1. **Fine-tune drafter**: Train a specialized smaller model on RAG tasks (as in the paper)\n",
    "2. **Smarter partitioning**: Use relevance scores to create better document subsets\n",
    "3. **Adaptive drafting**: Adjust number of drafts based on query complexity\n",
    "4. **Caching**: Cache document embeddings to speed up retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SPECULATIVE RAG PIPELINE VISUALIZATION\n",
      "================================================================================\n",
      "\n",
      "Question: What is quantum entanglement swapping and how does it work?\n",
      "\n",
      "┌─ STEP 1: RETRIEVAL\n",
      "│  Retrieved 6 documents\n",
      "│  Time: 2.18s\n",
      "│\n",
      "├─ STEP 2: PARTITIONING\n",
      "│  Subset 1: Docs [34, 1]\n",
      "│  Subset 2: Docs [33, 56]\n",
      "│  Subset 3: Docs [65, 2]\n",
      "│\n",
      "├─ STEP 3: PARALLEL DRAFTING (gpt-4o-mini)\n",
      "│  Generated 3 drafts in parallel\n",
      "│  Time: 3.18s\n",
      "│  Tokens: 3212\n",
      "│    Draft 1: Quantum entanglement swapping is a process that allows two p... (score: 0.9)\n",
      "│    Draft 2: The provided documents do not contain information about quan... (score: 0.2)\n",
      "│    Draft 3: Quantum entanglement swapping is a method of creating entang... (score: 0.7)\n",
      "│\n",
      "├─ STEP 4: VERIFICATION (gpt-4o)\n",
      "│  Evaluated all drafts\n",
      "│  Time: 6.06s\n",
      "│  Tokens: 3256\n",
      "│  Selected: Draft 1\n",
      "│  Confidence: 0.90\n",
      "│\n",
      "└─ FINAL ANSWER\n",
      "   Quantum entanglement swapping is a process that allows two parties, who have never interacted, to sh...\n",
      "\n",
      "Total Time: 11.42s\n",
      "Total Tokens: 6468\n"
     ]
    }
   ],
   "source": [
    "# Utility: Visualize the Speculative RAG pipeline for a result\n",
    "def visualize_pipeline(result: Dict[str, Any]):\n",
    "    \"\"\"Visualize the Speculative RAG pipeline flow.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SPECULATIVE RAG PIPELINE VISUALIZATION\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"Question: {result['question']}\\n\")\n",
    "    \n",
    "    # Step 1: Retrieval\n",
    "    print(\"┌─ STEP 1: RETRIEVAL\")\n",
    "    print(f\"│  Retrieved {len(result['retrieved_documents'])} documents\")\n",
    "    print(f\"│  Time: {result['timing']['retrieval']:.2f}s\")\n",
    "    print(\"│\")\n",
    "    \n",
    "    # Step 2: Partitioning\n",
    "    print(\"├─ STEP 2: PARTITIONING\")\n",
    "    for i, subset in enumerate(result['document_subsets']):\n",
    "        print(f\"│  Subset {i+1}: Docs {subset}\")\n",
    "    print(\"│\")\n",
    "    \n",
    "    # Step 3: Parallel Drafting\n",
    "    print(\"├─ STEP 3: PARALLEL DRAFTING (gpt-4o-mini)\")\n",
    "    print(f\"│  Generated {len(result['all_drafts'])} drafts in parallel\")\n",
    "    print(f\"│  Time: {result['timing']['drafting']:.2f}s\")\n",
    "    print(f\"│  Tokens: {result['tokens']['drafter_total']}\")\n",
    "    for i, draft in enumerate(result['all_drafts']):\n",
    "        score = next((s['score'] for s in result['draft_scores'] if s['draft_id'] == i), 'N/A')\n",
    "        print(f\"│    Draft {i+1}: {draft['answer'][:60]}... (score: {score})\")\n",
    "    print(\"│\")\n",
    "    \n",
    "    # Step 4: Verification\n",
    "    print(\"├─ STEP 4: VERIFICATION (gpt-4o)\")\n",
    "    print(f\"│  Evaluated all drafts\")\n",
    "    print(f\"│  Time: {result['timing']['verification']:.2f}s\")\n",
    "    print(f\"│  Tokens: {result['tokens']['verifier']}\")\n",
    "    best_idx = next(i for i, s in enumerate(result['draft_scores']) if s['score'] == max(s['score'] for s in result['draft_scores']))\n",
    "    print(f\"│  Selected: Draft {best_idx + 1}\")\n",
    "    print(f\"│  Confidence: {result['confidence_score']:.2f}\")\n",
    "    print(\"│\")\n",
    "    \n",
    "    # Final Answer\n",
    "    print(\"└─ FINAL ANSWER\")\n",
    "    print(f\"   {result['answer'][:100]}...\")\n",
    "    print()\n",
    "    \n",
    "    # Totals\n",
    "    print(f\"Total Time: {result['timing']['total']:.2f}s\")\n",
    "    print(f\"Total Tokens: {result['tokens']['total']}\")\n",
    "    \n",
    "\n",
    "# Example usage with a previous result\n",
    "if 'result' in locals():\n",
    "    visualize_pipeline(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- **Paper**: [Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting](https://research.google/blog/speculative-rag-enhancing-retrieval-augmented-generation-through-drafting/)\n",
    "- **Key Innovation**: Drafter-Verifier architecture where a smaller specialist model generates multiple answer drafts in parallel, and a larger model verifies and selects the best one\n",
    "- **Performance**: 12.97% accuracy improvement and 51% latency reduction on benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
