{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain -q\n",
    "%pip install youtube_transcript_api faiss-gpu -q \n",
    "%pip install langchain-google-genai -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS = GooglePalmEmbeddings()\n",
    "\n",
    "def create_db(video_url):\n",
    "  loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "  transcript = loader.load()\n",
    "\n",
    "  splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "  docs = splitter.split_documents(transcript)\n",
    "\n",
    "  return FAISS.from_documents(docs, EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(db, query, k=4):\n",
    "  docs = db.similarity_search(query, k=k)\n",
    "\n",
    "  page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "  llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
    "\n",
    "  prompt = PromptTemplate(\n",
    "      input_variables=[\"question\", \"docs\"],\n",
    "      template=\"\"\"\n",
    "        You are a helpful assistant that can answer questions about YouTube videos\n",
    "        based on the video's transcript. Given a question and a video transcript,\n",
    "        answer the question in a comprehensive and informative way,\n",
    "        using only the factual information from the transcript.\n",
    "\n",
    "        If you don't have enough information to answer the question, say \"I don't know.\"\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Transcript: {docs}\n",
    "        \"\"\",\n",
    "    )\n",
    "\n",
    "  chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "  response = chain.invoke({\"question\": query, \"docs\": page_content})\n",
    "\n",
    "  response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "  return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = 'https://www.youtube.com/watch?v=bSHp7WVpPgc'\n",
    "db = create_db(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video is about Hemanth HM, a Google developer expert for web technologies. He\n",
      "talks about his journey into coding, open-source, and how he balances his full-time\n",
      "work with his passion for open-source. He also provides some advice for those who\n",
      "want to become Google developer experts.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "query = \"Can you summarize the video?\"\n",
    "response, docs = query_db(db, query)\n",
    "print(textwrap.fill(response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the transcript, Hemanth HM describes open-source as a culture of free and openness\n",
      "in code, similar to the tradition of sharing recipes in India. He believes that code\n",
      "should be free and open to share and modify, allowing for innovation and\n",
      "collaboration.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are they saying about opensoruce?\"\n",
    "response, docs = query_db(db, query)\n",
    "print(textwrap.fill(response, width=85))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
